
<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>CoVT ‚Äî Project Page</title>
    <meta name="description" content="AI Paper Project Page" />
    <link rel="icon" href="static/image/logo.png" type="image/png" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&display=swap" rel="stylesheet" />
    <link rel="stylesheet" href="static/css/styles.css" />
  </head>
  <body class="sidebar-collapsed">
    
    <button class="sidebar-toggle" id="sidebarToggle" aria-label="ÂàáÊç¢ÁõÆÂΩï" aria-expanded="false">
      <span class="arrow" aria-hidden="true"></span>
    </button>

    <aside class="sidebar" id="sidebar">
      <div class="sidebar-inner glass">
        <div class="brand">CoVT</div>
        <nav class="toc">
          <a href="#hero" data-ease>Teaser</a>
          <a href="#abstract" data-ease>Abstract</a>
          <a href="#method" data-ease>Method</a>
          <a href="#anchor_visualization" data-ease>Anchor Visualization</a>
          <a href="#more-results" data-ease>More Results</a>
          <a href="#experiment-results" data-ease>Experiment Results</a>
        </nav>
      </div>
    </aside>

    <button id="backToTop" class="back-to-top" aria-label="Back to Top">
      <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2.5" stroke-linecap="round" stroke-linejoin="round">
        <path d="M18 15l-6-6-6 6"/>
      </svg>
    </button>

    <main class="main-shell">
      <section id="hero" class="section hero">
        <div class="hero-bg" aria-hidden="true"></div>
        <div class="hero-inner">
          <h1 class="title"><span class="title-highlight">Chain-of-Visual-Thought</span>: Teaching VLMs to See and Think Better with Continuous Visual Tokens</h1>
          <div class="author-block">
            <p class="author-list">
              <a href="https://wakals.github.io/" target="_blank" rel="noopener" class="author-link">Yiming Qin<sup>1</sup></a>,
              <a href="https://github.com/David-BominWei" target="_blank" rel="noopener" class="author-link">Bomin Wei<sup>2</sup></a>,
              <a href="https://gejiaxin.org/" target="_blank" rel="noopener" class="author-link">Jiaxin Ge<sup>1</sup></a>,
              <a href="https://tech-ai.panasonic.com/en/researcher_introduction/048/" target="_blank" rel="noopener" class="author-link">Konstantinos Kallidromitis<sup>3</sup></a>,<br/>
              <a href="https://stephanie-fu.github.io/" target="_blank" rel="noopener" class="author-link">Stephanie Fu<sup>1</sup></a>,
              <a href="https://people.eecs.berkeley.edu/~trevor/" target="_blank" rel="noopener" class="author-link">Trevor Darrell<sup>1</sup></a>,
              <a href="https://people.eecs.berkeley.edu/~xdwang/" target="_blank" rel="noopener" class="author-link">XuDong Wang<sup>1*</sup></a>
            </p>
            <p class="affiliation">UC Berkeley<sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; UCLA<sup>2</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Panasonic AI Research<sup>3</sup></p>
            <p class="affiliation note">*Corresponding author</p>
          </div>
          <div class="meta">
            </div>
          <div class="cta">
            <a class="btn primary" href="static/pdf/paper.pdf" target="_blank" rel="noopener">Paper</a>
            <a class="btn btn-arxiv" href="https://arxiv.org/abs/2511.19418" target="_blank" rel="noopener">arXiv</a>
            <a class="btn btn-code" href="https://github.com/Wakals/CoVT" target="_blank" rel="noopener">Code</a>
            <a class="btn btn-hf-model" href="https://huggingface.co/collections/Wakals/covt-chain-of-visual-thought" target="_blank" rel="noopener">HF Model</a>
            <a class="btn btn-hf-data" href="https://huggingface.co/datasets/Wakals/CoVT-Dataset" target="_blank" rel="noopener">HF Data</a>
          </div>
        </div>
        <figure class="teaser-figure">
          <img src="static/image/teaser.png" alt="Teaser Image" class="teaser-image" />
        </figure>
      </section>

      <section id="abstract" class="section container narrow reveal">
        <h2>Abstract</h2>
        <div class="abstract-card glass">
          <p>
            Vision‚ÄìLanguage Models (VLMs) excel at reasoning in linguistic space but struggle with perceptual understanding that requires dense visual perception, <em>e.g.</em>, spatial reasoning and geometric awareness. This limitation stems from the fact that current VLMs have limited mechanisms to capture dense visual information across spatial dimensions. We introduce <strong>Chain-of-Visual-Thought (CoVT)</strong>, a framework that enables VLMs to reason not only in words but also through <strong>continuous visual tokens</strong> ‚Äî compact latent representations that encode rich perceptual cues. Within a small budget of roughly <strong>20 tokens</strong>, CoVT distills knowledge from lightweight vision experts capturing complementary properties such as <strong>2D appearance, 3D geometry, spatial layout, and edge structure</strong>. During training, a VLM equipped with CoVT autoregressively predicts these visual tokens to reconstruct dense supervision signals (<em>e.g.</em>, depth, segmentation, edges, and DINO features). At inference, the model reasons directly in the continuous visual-token space, preserving efficiency while optionally decoding dense predictions for interpretability. Evaluated across more than <strong>ten diverse perception benchmarks</strong>, including CV-Bench, MMVP, RealWorldQA, MMStar, WorldMedQA, and HRBench, integrating CoVT into strong VLMs such as <strong>Qwen2.5-VL</strong> and <strong>LLaVA</strong> consistently improves performance by <strong>3% to 16%</strong>, demonstrating that compact continuous visual thinking enables more precise, grounded, and interpretable multimodal intelligence.
          </p>
        </div>
      </section>

      <section id="method" class="section container reveal">
        <div class="section-head">
          <h2>Method</h2>
          <p>
            CoVT generates interleaved discrete (textual) and continuous (visual) thinking tokens first, and then leverages these thinking tokens to condition next-token prediction and reason the final answer.
          </p>
        </div>
        <div class="method-visual glass">
          <img src="static/image/method.png" alt="CoVT Method Overview" class="method-visual-image" loading="lazy" />
          <div class="method-visual-note">
            <p>
              <strong>The training pipeline of CoVT.</strong> CoVT first generates the thinking process, containing visual thinking tokens, and then leverages these visual thoughts to condition next-token prediction and reason the final answer. To endow these tokens with perceptual meaning, we align them with lightweight vision experts (SAM, DepthAnything, PIDINet, DINO) on their respective tasks during training. Specifically: SAM uses 8 visual tokens as mask prompts; DepthAnything uses 4 tokens to reconstruct depth; PIDINet uses 4 tokens to reconstruct edges; and DINO uses 4 tokens to match patch-level features. The VLM is finetuned with LoRA and all projection layers are trainable. <em>Note: During inference, dense predictions are decoded only when interpretability is desired; otherwise, reasoning occurs entirely in the latent visual space.</em>
            </p>
          </div>
        </div>
        <div class="method-experience glass">
          <div class="method-hint">üëÄ Explore how each type of CoVT token contributes to reasoning</div>
          <div class="method-track" role="tablist" aria-label="Anchor token tasks">
            <button class="method-node active" data-method="sam">
              <span class="method-node-dot"></span>
              <span class="method-node-label">Segmentation</span>
            </button>
            <button class="method-node" data-method="depth">
              <span class="method-node-dot"></span>
              <span class="method-node-label">Depth</span>
            </button>
            <button class="method-node" data-method="pidinet">
              <span class="method-node-dot"></span>
              <span class="method-node-label">Edge</span>
            </button>
            <button class="method-node" data-method="dino">
              <span class="method-node-dot"></span>
              <span class="method-node-label">DINO</span>
            </button>
          </div>
          <div class="method-detail" id="methodDetail">
            <div id="methodContent" class="method-content fade-in">
              <p class="method-detail-eyebrow" id="methodBadge">01 ¬∑ 2D Perception</p>
              <h3 id="methodTitle">Segmentation Tokens ¬∑ SAM</h3>
              <p id="methodCopy">
                Segmentation tokens capture instance-level masks, equipping VLMs with the 2D perception capability.
              </p>
              <ul id="methodBullets">
                <li>8 segmenation tokens are aligned to the SAM decoder-space at the prompt-level.</li>
                <li>During training, the decoded masks are supervised by using Hungarian Mathing algorithm, along with the cost function of dice loss and focal loss.</li>
              </ul>
            </div>
          </div>
        </div>
      </section>

      <section id="anchor_visualization" class="section container reveal">
        <div class="section-head">
          <h2>Multiple CoVT Tokens Visualization</h2>
          <p>Different CoVT tokens contribute complementary cues that enable the model to solve complex perceptual reasoning tasks.</p>
        </div>

        <div class="anchor-lab glass">
          <div class="anchor-controls">
            <div class="variant-picker-wrap">
                <div class="variant-picker" id="variantPicker" role="tablist" aria-label="ÈÄâÊã©ÁºñËæëÁâàÊú¨">
                <button role="tab" aria-selected="true" data-variant="v4" class="chip">Demo 1</button>
                <button role="tab" aria-selected="false" data-variant="v1" class="chip">Demo 2</button>
                <button role="tab" aria-selected="false" data-variant="v2" class="chip">Demo 3</button>
                <button role="tab" aria-selected="false" data-variant="v3" class="chip">Demo 4</button>
                </div>
            </div>
            <p class="anchor-note"
              style="text-align: center; padding: 12px 18px; 
                      background: linear-gradient(90deg, #e6f9ff, #ffffff); 
                      border-left: 4px solid #3be3f6; font-weight: 600;">
              Click different <code class="tag tag-visual-token">&lt;CoVT Tokens&gt;</code> to view the decoded visualization results.
            </p>
          </div>

          <div class="anchor-panels-container">
              <div class="vc-panel anchor-panel fade-item visible" data-variant="v4">
                <div class="variant-row variant-row-split">
                    <figure class="variant-visual">
                    <img src="static/image/demos/multi/4/origin.png" alt="demo1 visual" class="variant-image" />
                    </figure>
                    <div class="variant-copy variant-copy-split">
                    <div class="qa-block question-block">
                        <div class="qa-label qa-label-question">Question</div>
                        <p class="qa-text">Describe the scene in the picture in detail, and find out how many clouds are there in the sky.</p>
                    </div>
                    </div>
                </div>
                <div class="qa-block answer-block qa-block-wide">
                  <div class="qa-label qa-label-answer">Answer</div>
                  <p class="qa-text">
                    <code class="tag tag-think">&lt;Think&gt;</code>
                    Because the segmentation of the image is <code class="token token-sam">&lt;SEGMENT Token&gt;</code>, the depth map of the image is <code class="token token-depth">&lt;DEPTH Token&gt;</code>, and the edge map of the image is <code class="token token-edge">&lt;EDGE Token&gt;</code>.
                    <code class="tag tag-think">&lt;/Think&gt;</code><br/><br/>
                    <code class="tag tag-answer">&lt;Answer&gt;</code>
                    The image depicts a charming, handcrafted scene featuring a small doll-like figure standing on a grassy patch. The figure is dressed in an orange outfit with matching boots, and it has a cheerful expression. The doll is holding a stick with a smiling sun at the top, which appears to be made from felt or similar material. <br/>In the background, there are two green felt trees, each with a simple triangular shape and a brown trunk. Above the trees, there are four fluffy white clouds, each adorned with a brown button-like detail. The sky is painted in a soft blue color, providing a serene backdrop for the scene. <br/>The overall composition is whimsical and playful, likely intended to evoke a sense of joy and innocence. The use of bright colors and simple shapes contributes to the overall aesthetic appeal of the image. <br/>To answer the question about the number of clouds: There are <strong>four clouds</strong> visible in the sky above the trees.
                    <code class="tag tag-answer">&lt;/Answer&gt;</code>
                  </p>
                </div>
              </div>

              <div class="vc-panel anchor-panel fade-item" data-variant="v1">
                <div class="variant-row">
                    <figure class="variant-visual">
                    <img src="static/image/demos/multi/1/origin.png" alt="demo1 visual" class="variant-image" />
                    </figure>
                    <div class="variant-copy">
                    <div class="qa-block question-block">
                        <div class="qa-label qa-label-question">Question</div>
                        <p class="qa-text">Two points are circled on the image, labeled by A and B. Which point is closer to the camera?</p>
                    </div>
                    <div class="qa-block answer-block">
                        <div class="qa-label qa-label-answer">Answer</div>
                        <div>
                        <p class="qa-text">
                            <code class="tag tag-think">&lt;Think&gt;</code>
                            Because the segmentation of the image is <code class="token token-seg">&lt;SEGMENT Token&gt;</code>, the depth map of the image is <code class="token token-depth">&lt;DEPTH Token&gt;</code>.
                            <code class="token token-seg">&lt;SEGMENT Token&gt;</code>
                            <code class="tag tag-think">&lt;/Think&gt;</code>
                        </p>
                        <p class="qa-text qa-text-strong">
                            <code class="tag tag-answer">&lt;Answer&gt;</code>
                            The answer is the <strong>point B</strong>.
                            <code class="tag tag-answer">&lt;/Answer&gt;</code>
                        </p>
                        </div>
                    </div>
                    </div>
                </div>
              </div>

              <div class="vc-panel anchor-panel fade-item" data-variant="v2">
                <div class="variant-row">
                    <figure class="variant-visual">
                    <img src="static/image/demos/multi/2/origin.jpg" alt="demo2 visual" class="variant-image" />
                    </figure>
                    <div class="variant-copy">
                    <div class="qa-block question-block">
                        <div class="qa-label qa-label-question">Question</div>
                        <p class="qa-text">Which object is closer to the camera: the books (red box) or the chair (blue box)?</p>
                    </div>
                    <div class="qa-block answer-block">
                        <div class="qa-label qa-label-answer">Answer</div>
                        <div>
                        <p class="qa-text">
                            <code class="tag tag-think">&lt;Think&gt;</code>
                             The depth map of the image is <code class="token token-depth">&lt;DEPTH Token&gt;</code>, and the edge map of the image is <code class="token token-edge">&lt;EDGE Token&gt;</code>.
                            <code class="tag tag-think">&lt;/Think&gt;</code>
                        </p>
                        <p class="qa-text qa-text-strong">
                            <code class="tag tag-answer">&lt;Answer&gt;</code>
                            The <strong>books are closer to the camera</strong> than the chair.
                            <code class="tag tag-answer">&lt;/Answer&gt;</code>
                        </p>
                        </div>
                    </div>
                    </div>
                </div>
              </div>
              
              <div class="vc-panel anchor-panel fade-item" data-variant="v3">
                <div class="variant-row">
                    <figure class="variant-visual">
                    <img src="static/image/demos/multi/3/origin.jpg" alt="demo4 visual" class="variant-image" />
                    </figure>
                    <div class="variant-copy">
                    <div class="qa-block question-block">
                        <div class="qa-label qa-label-question">Question</div>
                        <p class="qa-text">How many white vertical lines are drawn on the ground?</p>
                    </div>
                    <div class="qa-block answer-block">
                        <div class="qa-label qa-label-answer">Answer</div>
                        <div>
                        <p class="qa-text">
                            <code class="tag tag-think">&lt;Think&gt;</code>
                            Because the segmentation of the image is <code class="token token-seg">&lt;SEGMENT Token&gt;</code>, the edge map of the image is <code class="token token-edge">&lt;EDGE Token&gt;</code>.
                            <code class="tag tag-think">&lt;/Think&gt;</code>
                        </p>
                        <p class="qa-text qa-text-strong">
                            <code class="tag tag-answer">&lt;Answer&gt;</code>
                            There are <strong>five white vertical lines</strong>.
                            <code class="tag tag-answer">&lt;/Answer&gt;</code>
                        </p>
                        </div>
                    </div>
                    </div>
                </div>
              </div>
          </div>

          <div class="anchor-playground glass">
            <div class="anchor-playground-head">
              <h3>Token Playground</h3>
              <p>Drag the slider to view the decoded visualization results.</p>
            </div>
            <div class="compare-grid" id="anchorCompareGrid" data-mode="dual">
              <div class="compare-wrap" data-slot="primary">
                 <div class="compare-container js-compare-container">
                    <img class="img-back js-original" alt="Original" />
                    <span class="label-badge original">Original</span>

                    <div class="img-front-wrapper js-front-wrapper">
                        <img class="img-front js-editedA" alt="Edited" />
                    </div>
                    <span class="label-badge edited js-visualTokenTag" data-slot="primary">Visual Token</span>

                    <div class="handle js-handle">
                        <div class="handle-line"></div>
                        <div class="handle-circle">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                              <path d="M9 6l-5 6 5 6" />
                              <path d="M15 6l5 6-5 6" />
                            </svg>
                        </div>
                    </div>
                 </div>
              </div>

              <div class="compare-wrap" data-slot="secondary">
                 <div class="compare-container js-compare-container">
                    <img class="img-back js-original" alt="Original" />
                    <span class="label-badge original">Original</span>
                    <div class="img-front-wrapper js-front-wrapper">
                        <img class="img-front js-editedB" alt="Edited" />
                    </div>
                    <span class="label-badge edited js-visualTokenTag" data-slot="secondary">Visual Token</span>
                    <div class="handle js-handle">
                        <div class="handle-line"></div>
                        <div class="handle-circle">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                              <path d="M9 6l-5 6 5 6" />
                              <path d="M15 6l5 6-5 6" />
                            </svg>
                        </div>
                    </div>
                 </div>
              </div>

              <div class="compare-wrap" data-slot="tertiary">
                 <div class="compare-container js-compare-container">
                    <img class="img-back js-original" alt="Original" />
                    <span class="label-badge original">Original</span>
                    <div class="img-front-wrapper js-front-wrapper">
                        <img class="img-front js-editedC" alt="Edited" />
                    </div>
                    <span class="label-badge edited js-visualTokenTag" data-slot="tertiary">Visual Token</span>
                    <div class="handle js-handle">
                        <div class="handle-line"></div>
                        <div class="handle-circle">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                              <path d="M9 6l-5 6 5 6" />
                              <path d="M15 6l5 6-5 6" />
                            </svg>
                        </div>
                    </div>
                 </div>
              </div>
            </div>
          </div>
        </div>
      </section>

      <section id="single_visualization" class="section container reveal">
        <div class="section-head">
          <h2>Single CoVT Token Visualization</h2>
          <p>Inspect how a single type of CoVT token guides reasoning.</p>
        </div>
        <div class="single-lab glass mobile-full">
          <div class="single-picker-wrap">
            <div class="variant-picker" id="singlePicker" role="tablist" aria-label="ÈÄâÊã©Âçï‰∏Ä token">
              <button role="tab" aria-selected="true" data-single="s1" class="chip">Demo 1</button>
              <button role="tab" aria-selected="false" data-single="s2" class="chip">Demo 2</button>
              <button role="tab" aria-selected="false" data-single="s3" class="chip">Demo 3</button>
              <button role="tab" aria-selected="false" data-single="s4" class="chip">Demo 4</button>
            </div>
          </div>

          <div class="single-grid">
            <figure class="single-visual">
              <img src="static/image/demos/single/1/origin.png" alt="Single token reference" class="single-image js-single-still" />
              <span class="label-badge original">Original</span>
            </figure>
            <div class="single-playground">
              <div class="compare-container js-compare-container">
                <img class="img-back js-single-orig" alt="Original" />
                <span class="label-badge original">Original</span>

                <div class="img-front-wrapper js-front-wrapper">
                  <img class="img-front js-single-token" alt="Visual Token" />
                </div>
                <span class="label-badge edited js-single-token-label">Segment Token</span>

                <div class="handle js-handle">
                  <div class="handle-line"></div>
                  <div class="handle-circle">
                    <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                      <path d="M9 6l-5 6 5 6" />
                      <path d="M15 6l5 6-5 6" />
                    </svg>
                  </div>
                </div>
              </div>
            </div>
          </div>

          <div class="single-qa">
            <div class="qa-block question-block">
              <div class="qa-label qa-label-question">Question</div>
              <p class="qa-text" id="singleQuestion">‚Äî</p>
            </div>
            <div class="qa-block answer-block">
              <div class="qa-label qa-label-answer">Answer</div>
              <p class="qa-text" id="singleAnswer">‚Äî</p>
            </div>
          </div>
        </div>
      </section>

      <section id="more-results" class="section container reveal">
        <div class="section-head">
          <h2>Gallery</h2>
          <p>Click arrows to navigate through reasoning examples.</p>
        </div>
          <div class="results-module glass mobile-full" data-results>
          <button class="results-nav prev" data-results-prev aria-label="‰∏ä‰∏ÄÂº†">‚Äπ</button>
          <div class="results-stage">
            <div class="results-track" id="resultsTrack"></div>
          </div>
          <button class="results-nav next" data-results-next aria-label="‰∏ã‰∏ÄÂº†">‚Ä∫</button>
          <div class="results-caption glass">
            <div class="qa-block question-block compact">
              <div class="qa-label qa-label-question">Question</div>
              <p class="qa-text" id="resultsQuestion">‚Äî</p>
            </div>
            <div class="qa-block answer-block compact">
              <div class="qa-label qa-label-answer">Answer</div>
              <div id="resultsAnswer"></div>
            </div>
          </div>
        </div>
      </section>

      <section id="experiment-results" class="section container reveal">
        <h2>Experiment Results</h2>
        <div class="exp-grid">
          <figure class="exp-card exp-card-wide">
            <img src="static/image/main_exp.png" alt="Major Benchmarks" loading="lazy" />
            <figcaption><strong>Comparison of CoVT with the baseline and closed-source models.</strong> CoVT delivers consistent improvements across all vision-centric benchmarks and further reveals that each visual token type contributes most effectively to the tasks related to its rich information.</figcaption>
          </figure>
          <div class="exp-card exp-card-half">
            <img src="static/image/more_exp_1.png" alt="More Experiments 1" loading="lazy" />
            <figcaption><strong>Comparison between CoVT and Aurora based on LLaVA-v1.5-13B.</strong> &dagger; indicates our reproduced results based on the provided checkpoints.</figcaption>
          </div>
          <div class="exp-card exp-card-half">
            <img src="static/image/more_exp_2.png" alt="More Experiments 2" loading="lazy" />
            <figcaption>Beyond the gains on vision-centric benchmarks, CoVT also achieves slight improvements on <strong>non‚Äìvision-centric tasks</strong>.</figcaption>
          </div>
        </div>
      </section>

      <section id="bibtex" class="section container reveal">
        <h2>BibTeX</h2>
        <div class="code-block">
          <pre><code>@article{qin2025chain,
  title={Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens},
  author={Qin, Yiming and Wei, Bomin and Ge, Jiaxin and Kallidromitis, Konstantinos and Fu, Stephanie and Darrell, Trevor and Wang, Xudong},
  journal={arXiv preprint arXiv:2511.19418},
  year={2025}
}</code></pre>
        </div>
      </section>

      <footer class="footer container">
        <p>2025 CoVT. Crafted with ‚ù§Ô∏è.</p>
        <div class="footer-links">
          <a href="#" aria-label="arXiv" class="footer-icon">
            <svg viewBox="0 0 24 24" aria-hidden="true">
              <path d="M4 4h4l4 6 4-6h4l-6.5 9.5L21 20h-4l-5-6.5L7 20H3l7.5-10.5z"/>
            </svg>
          </a>
          <a href="https://github.com/Wakals/CoMT" target="_blank" rel="noopener" aria-label="GitHub" class="footer-icon">
            <svg viewBox="0 0 24 24" aria-hidden="true">
              <path d="M12 .5a12 12 0 0 0-3.8 23.4c.6.1.8-.3.8-.6v-2.1c-3.3.7-4-1.6-4-1.6-.5-1.2-1.1-1.5-1.1-1.5-.9-.6.1-.6.1-.6 1 .1 1.5 1 1.5 1 .9 1.5 2.4 1 3 .8.1-.7.3-1 .6-1.3-2.6-.3-5.3-1.3-5.3-5.7 0-1.3.5-2.3 1.2-3.1-.1-.3-.5-1.5.1-3 0 0 1-.3 3.2 1.2a10.9 10.9 0 0 1 5.8 0c2.2-1.5 3.2-1.2 3.2-1.2.6 1.5.2 2.7.1 3 .8.8 1.2 1.8 1.2 3.1 0 4.4-2.7 5.4-5.3 5.7.4.4.7 1 .7 2v3c0 .3.2.7.8.6A12 12 0 0 0 12 .5"/>
            </svg>
          </a>
          <a href="#" aria-label="Zhihu" class="footer-icon">
            <svg viewBox="0 0 24 24" aria-hidden="true">
              <path d="M4.2 4h15.5c.5 0 .8.3.8.7v14.6c0 .4-.3.7-.8.7H4.2c-.5 0-.8-.3-.8-.7V4.7c0-.4.3-.7.8-.7zm2.7 9.8h1.7l.4-1.5h2.4l.4 1.5h1.7l-2.6-8h-1.4zm2.5-2.9.8-2.8.8 2.8zm5.9 4.6c1.2 0 2.3-.6 2.9-1.5l-1.1-.7a1.5 1.5 0 0 1-1.8.6c-.6-.2-1-.7-1-1.3 0-.8.7-1.5 1.6-1.5.4 0 .8.2 1 .4l1.1-.7a3 3 0 0 0-2-.7 3 3 0 0 0-3 2.5c-.4 1.6.6 3 2.3 3z"/>
            </svg>
          </a>
          <a href="#" aria-label="X" class="footer-icon">
            <svg viewBox="0 0 24 24" aria-hidden="true">
              <path d="M3 3h4.6l4.2 5.8L15.8 3H21l-6.6 8.7L21.5 21h-4.6l-4.6-6.3L7.4 21H3.1l7-9.2z"/>
            </svg>
          </a>
        </div>
      </footer>
    </main>

    <div id="tokenPopover" class="token-popover" aria-hidden="true">
      <div class="token-popover-inner">
        <img id="tokenPopoverImage" alt="Token preview" />
      </div>
      <span class="token-popover-arrow"></span>
    </div>

    <script src="static/js/script.js"></script>
  </body>
</html>